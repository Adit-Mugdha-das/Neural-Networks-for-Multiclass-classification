# Neural Networks for Multiclass Classification

This assignment implements a vectorized neural network for multiclass classification using softmax activation and one-hot encoded labels.  
It is part of **Week 2 (Course 2: Advanced Learning Algorithms)** from the **Machine Learning Specialization** by **Andrew Ng** on Coursera.

##  Description

In this lab, I built a simple neural network from scratch to classify input data into one of several categories. The model uses **softmax activation** in the output layer and optimizes the multiclass **cross-entropy loss** through **backpropagation** and **gradient descent**.

### Key Concepts Covered:
- Neural network for multiclass classification
- One-hot encoding of target classes
- Softmax activation for output layer
- Multiclass cross-entropy loss
- Forward and backward propagation (vectorized)
- Gradient descent updates for all layers

##  Files Included

- `multiclass_classification_lab.ipynb`: Main notebook with full implementation
- `lab_utils_softmax.py`: Utility functions for forward/backward steps, loss, and accuracy
- `data/`: Contains training and evaluation datasets

> ⚠️ This repository contains only my own implementation and abides by Coursera’s Honor Code.

##  Tools Used

- Python 3
- NumPy
- Matplotlib
- Jupyter Notebook

##  Course Info

This assignment is part of:
> [Machine Learning Specialization](https://www.coursera.org/specializations/machine-learning-introduction)  
> Instructor: **Andrew Ng**  
> Course 2: Advanced Learning Algorithms  
> Week 2: Backpropagation and Multiclass Softmax Classification

##  License

This repository is meant for educational and portfolio use only. Do not submit it directly on Coursera.

---

⭐ Star the repo if you're enjoying the learning journey in machine learning!
